# Fraud Detection - Credit Card Transactions

Проект по обнаружению мошеннических операций с кредитными картами с использованием машинного обучения.

## Структура проекта

- `EDA.ipynb` - разведочный анализ данных 
- `baseline1.ipynb` - базовые модели и эксперименты  
- `hyperparam_tuning.ipynb` - тонкая настройка гиперпараметров с Optuna (не дала результатов)
- `improvements.ipynb` - улучшения моделей 



## Постановка задачи
**Цель:** Предсказать мошеннические операции с кредитными картами в режиме реального времени.

**Таргет:** `Class` (0 - легитимная операция, 1 - мошенническая)

**Данные:** 284,807 транзакций, из них 492 мошеннических (0.17%)

**Фичи:**
- `V1-V28` - анонимизированные PCA признаки
- `Time` - время в секундах от первой транзакции
- `Amount` - сумма транзакции

**Основная метрика:** AUPRC (Precision-Recall AUC) из-за сильного дисбаланса классов

## EDA: Анализ и преобразования данных

### Ключевые находки:
- **Экстремальный дисбаланс** - соотношение классов 578:1
- **Amount** имеет сильно скошенное распределение
- **Time** требует циклического преобразования из-за суточных паттернов
- **Выбросы** присутствуют в большинстве признаков
- **Низкая мультиколлинеарность** - VIF в основном <5

### Примененные преобразования:
1. **`log_amount`** - логарифмирование суммы для нормализации распределения
2. **`cos_time`** - косинусное преобразование времени для учета суточной цикличности
3. Удалены исходные `Time` и `Amount`

### Статистические инсайты:
- **Сильные предикторы:** V4, V11, V14, V17 (высокая корреляция с таргетом)
- **Слабые предикторы:** V8, V13, V15, V22, V23, V25
- **Временные паттерны:** мошеннические операции имеют неравномерное распределение по времени

## Baseline: Сравнение моделей

<img width="296" height="80" alt="image" src="https://github.com/user-attachments/assets/2ba0daf1-bb27-40a7-b1c1-3d586bb8cf28" />
- Изначально, по бейзлайну наилучший результат показывал RandomForest, однако я бы не стал ее использовать при решении реальной задачи, т.к. нет scale_pos_weight, early_stopping, хуже выявляет нелинейные зависимости, в отличии от бустинговых моделей, да и то же время инференса на бОльших данных будет больше. 

### Важности фич по моделям:

**XGBoost (топ-5):**
1. **V14** (0.128)
2. **V4** (0.095) 
3. **V17** (0.079)
4. **V10** (0.069)
5. **V12** (0.067)

**Random Forest (топ-5):**
1. **V17** (0.145)
2. **V14** (0.132)
3. **V12** (0.098)
4. **V10** (0.085)
5. **V16** (0.072)

**Вывод по baseline:** XGBoost показал наилучшие результаты по всем метрикам, особенно по precision (94.1%), что критично для фрод-детекшена.

## Improvements:

### Проверенные подходы:
1. **Feature selection по XGBoost importance** - удаление признаков с importance < 0.01
2. **Feature selection по SHAP importance** - удаление признаков с SHAP < 0.3  
3. **Clipping выбросов по IQR** - для топ-5 признаков
4. **Методы балансировки** (SMOTE, ADASYN, RandomUnderSampling)

### Результаты экспериментов:

| Метод | Features | AUPRC | F1-Score | Результат |
|-------|----------|-------|----------|-----------|
| Baseline XGBoost | 30 | 0.8803 | 0.8392 | **Лучший** |
| XGB_Reduced | 25 | 0.8781 | 0.8347 | -0.2% |
| SHAP_Reduced | 26 | 0.8791 | 0.8380 | -0.1% |
| Clipped_IQR | 30 | 0.8756 | 0.8296 | -0.5% |
| SMOTE | 30 | 0.8623 | 0.8124 | -2.0% |
| ADASYN | 30 | 0.8589 | 0.8087 | -2.4% |

### Выводы по улучшениям:
- **Удаление признаков ухудшает качество** - даже слабые признаки содержат полезную информацию
- **Clipping выбросов вреден** - выбросы содержат паттерны мошенничества, поэтому обрезание выбросов по IQR ухудшает целевую метрику
- **Методы oversampling ухудшают результаты** - создают искусственные слишком шумные данные
- **Baseline XGBoost оптимален** - проще в поддержке и показывает лучшее качество
-  Лучшее качество дал Class Weight, я связываю это со спецификой метода. Функция потерь дополнительно учитывает коэффициент дисбаланса между классами, то есть штраф за ошибку на минорном классе намного больше.
  Другие методы саязаны с изменением данных, что плохо сказывается на качестве, мы не знаем изначальной сути признаков, которые были получены с помощью PCA.

## Гиперпараметры: Тюнинг с Optuna
Тюнинг гиперпараметров не дал результатов, не нашелся оптимум. 
### Методология:
- **Алгоритм:** TPE Sampler + Hyperband Pruner
- **Валидация:** 3-fold Stratified CV
- **Масштаб:** 300 trials, 4 часа времени
- **Метрика:** AUPRC

### Диапазоны поиска:
- `max_depth`: 2-20
- `learning_rate`: 0.0005-0.7 (log)
- `subsample/colsample`: 0.6-1.0
- `reg_alpha/lambda`: 0-35
- `gamma`: 0-20

### Лучшие параметры из тех что имеем:
{
    'max_depth': 8,
    'learning_rate': 0.1,
    'subsample': 0.8, 
    'colsample_bytree': 0.8,
    'reg_alpha': 10,
    'reg_lambda': 15,
    'min_child_weight': 5,
    'gamma': 2,
    'max_delta_step': 1
}



